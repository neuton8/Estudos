<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CE_1.2_por vb</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="estudo-de-caso-1.2">Estudo de caso 1.2</h1>
<img src="https://drive.google.com/uc?export=view&amp;id=1du2bbjAM4VMziHc2jl9Etk7q26IxuLyy">
<h2 id="análise-de-lda-alocação-latente-de-dirichlet">Análise de LDA (<em>Alocação Latente de Dirichlet</em>)</h2>
<p><strong>Docente</strong>: Tamara Broderick<br>
<strong>TA</strong>: Qiuying (Giulia) Lai</p>
<h3 id="instruções-de-execução">Instruções de execução</h3>
<blockquote>
<h4 id="google-colab-recomendado">Google Colab (recomendado)</h4>
<p>Caso queira executar o estudo de caso em Python sem precisar instalar um programa/arquivo em seu computador, faça o que está descrito a seguir:</p>
<ol>
<li>Acesse o seguinte <em>notebook</em> do Google Colab:  <a href="https://drive.google.com/file/d/1ro3pEbre4NOCVUC4f2qjHntNDOynycBu/view?usp=sharing">CE_1.2.ipynb</a></li>
<li>Escolha a opção “Abrir com Google Colaboratory”</li>
<li>Copie o <em>notebook</em> em seu próprio Google Drive (pode-se executar o código sem realizar esta etapa porém as alterações não ficarão salvas se parte do código for modificado) --&gt; “Copiar no Drive”</li>
</ol>
</blockquote>
<br>
<blockquote>
<p><strong>Nota</strong>: você pode acessar o repositório do projeto original no qual se baseia este estudo de caso pelo link: <a href="https://github.com/qlai/stochasticLDA">github.com/qlai/stochasticLDA</a></p>
</blockquote>
<hr>
<h3 id="introdução">Introdução</h3>
<p>Neste documento, revisamos algumas dicas úteis para ajudá-lo a realizar sua própria análise de temas em diferentes textos, neste caso, resumos de artigos científicos de professores do departamento de <em>Electrical Engineering and Computer Science</em> do MIT, usando a inferência variacional estocástica (<em>SVI</em>) em <em>LDA</em> (Alocação Latente de Dirichlet). Forneceremos exemplos para sua implementação na linguagem de programação Python. Falaremos sobre:</p>
<ol>
<li>Obtenção de seu próprio conjunto de dados mediante técnicas de mineração de dados</li>
<li>Pré-processamento do conjunto de dados</li>
<li>Aplicação da <em>LDA</em></li>
<li>Visualização dos resultados</li>
</ol>
<h3 id="dados">Dados</h3>
<p>Com a biblioteca de <em>web scraping</em> (um tipo de mineração de dados) <a href="https://www.crummy.com/software/BeautifulSoup/"><code>BeautifulSoup</code></a> e analisando a estrutura do código fonte do portal de artigos científicos <a href="https://arxiv.org/"><em>arXiv</em></a>, você pode extrair da internet a lista de nomes dos membros do corpo docente do departamento de <em>Electrical Engineering and Computer Science</em> do MIT e, com essa informação, realizar consultas em <a href="https://arxiv.org/"><em>arXiv</em></a> de forma automática, criando um banco de dados de milhares de artigos em minutos.</p>
<p>Acesse um exemplo guiado de como realizar esta etapa no <a href="https://drive.google.com/file/d/1wsetPOOjohkJPuM-YoKGxm_EpRodrO1X/view?usp=sharing"><em>notebook</em></a> de Python associado a este estudo de caso.</p>
<h3 id="implementando-seu-próprio-esquema-lda-svi">Implementando seu próprio esquema <em>LDA-SVI</em></h3>
<p>A Alocação Latente de Dirichlet (<em>LDA</em>) é um modelo estatístico generativo de processamento de linguagem natural (<em>PNL</em>) usado para descobrir “temas” em um grande conjunto de documentos. Esta ideia foi introduzida pela primeira vez por David Blei, Andrew Ng e Michael Jordan <a href="#refer%C3%AAncias">[1]</a>.</p>
<p>A ideia principal é que, se você considerar um “tema” como um conjunto de certas palavras, poderá considerar cada documento como um conjunto de temas. A proporção de cada tema no documento dependerá da proporção de palavras no documento que estão associadas a esse tema. Por exemplo, o tema “esportes” pode ser composto por palavras como tênis, futebol e ginástica.</p>
<p>Ao receber um conjunto de documentos, você pode calcular a distribuição <em>subsequente</em> dos temas. No artigo da <em>LDA</em> original, é usado um algoritmo de descida de coordenadas para inferência variacional de campo médio (<em>coordinate descent algorithm for mean-field variational inference</em>) e, posteriormente, os pesquisadores usaram também a amostragem de Gibbs e a propagação de expectativas.</p>
<p>Neste tutorial, no entanto, será abordada apenas a inferência variacional estocástica (em inglês, <em>Stochastic Variational Inference</em>, ou <em>SVI</em>) da LDA. A <em>SVI</em> foi publicada pela primeira vez em 2013 por Matt Hoffman, David Blei, Chong Wang e John Paisley <a href="#refer%C3%AAncias">[2]</a>.  A inferência variacional de descida de coordenadas tradicional requer que cada atualização seja realizada em todos os dados, e essas atualizações acabam sendo ineficientes à medida que o conjunto de dados cresce, uma vez que cada atualização aumenta linearmente com o tamanho dos dados.</p>
<p>A ideia principal da <em>SVI</em> é atualizar os parâmetros variacionais globais com mais frequência. Com parâmetros locais e globais e, levando em consideração o conjunto de dados com um número conhecido de pontos de dados, pode-se pegar aleatoriamente um ponto de dados por vez, atualizar o parâmetro local e projetar a alteração nos parâmetros globais. A inferência variacional de descida de coordenadas tradicional se repete até que o resultado convirja; ou seja, até que a alteração nos parâmetros globais se torne menor do que um valor específico.</p>
<h4 id="notação">Notação</h4>
<p>Aqui proporcionamos uma visão geral breve das variáveis de entrada para a <em>LDA</em> e a <em>SVI</em>. As variáveis que podem ser estabelecidas são:</p>
<ul>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">λ</span></span></span></span></span>: o que se deseja obter no final (a distribuição posterior de temas para cada palavra).</p>
</li>
<li>
<p><code>vocab</code>: vocabulário geral que será obtido nos documentos.</p>
</li>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span></span></span></span></span>: quantidade de temas que se deseja conseguir no final.</p>
</li>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span></span></span></span></span>: quantidade total de documentos.</p>
</li>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span></span></span></span></span>: parâmetro para a distribuição de temas por documento.</p>
</li>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">η</span></span></span></span></span>: parâmetro para a distribuição de vocabulário por tema.</p>
</li>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">T</span></span></span></span></span>: atraso que reduz as primeiras iterações.</p>
</li>
<li>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>κ</mi></mrow><annotation encoding="application/x-tex">\kappa</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">κ</span></span></span></span></span>: taxa de esquecimento, controla a velocidade com que a informação antiga é esquecida; quanto maior o valor, mais lenta.</p>
</li>
<li>
<p><code>max.iterations</code>: a quantidade de iteraciones máxima que as atualizações podem fazer. Normalmente, se estabelece um controle de forma que, se a diferença de dois valores consecutivos de <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">λ</span></span></span></span></span> for menor do que um valor específico, o algoritmo seja considerado convergente. No entanto, visto que às vezes esse valor específico poderia ser definido muito baixo, é definido um valor de iteração máximo para interromper as atualizações.</p>
</li>
</ul>
<h4 id="modelo-generativo-da-lda">Modelo generativo da <em>LDA</em></h4>
<p>A seguir, revisaremos o modelo generativo da <em>LDA</em>. A <em>LDA</em> pressupõe que cada documento tem <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span></span></span></span></span> temas com distintas proporções. A <em>LDA</em> molda um corpus de textos <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span></span></span></span></span> de tamanho <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span></span></span></span></span> do seguinte modo:</p>
<ul>
<li>
<p>Extrai a distribuição sobre o vocabulário <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>β</mi><mi>k</mi></msub><mo>∼</mo><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">h</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">t</mi></mrow><mo stretchy="false">(</mo><mi>η</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\beta_k \sim \mathrm{Dirichlet}(\eta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.05278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">D</span><span class="mord mathrm">i</span><span class="mord mathrm">r</span><span class="mord mathrm">i</span><span class="mord mathrm">c</span><span class="mord mathrm">h</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.03588em;">η</span><span class="mclose">)</span></span></span></span></span> para os temas <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1...</mn><mi>K</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">k \in \{1...K\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.73354em; vertical-align: -0.0391em;"></span><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right: 0.07153em;">K</span><span class="mclose">}</span></span></span></span></span></p>
</li>
<li>
<p>Para cada documento <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>1...</mn><mi>D</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">d \in \{1...D\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.73354em; vertical-align: -0.0391em;"></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{</span><span class="mord">1</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="mclose">}</span></span></span></span></span>:</p>
<ul>
<li>Extrai as proporções do tema <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>∼</mo><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">h</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">t</mi></mrow><mo stretchy="false">(</mo><mi>α</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d \sim \mathrm{Dirichlet}(\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">D</span><span class="mord mathrm">i</span><span class="mord mathrm">r</span><span class="mord mathrm">i</span><span class="mord mathrm">c</span><span class="mord mathrm">h</span><span class="mord mathrm">l</span><span class="mord mathrm">e</span><span class="mord mathrm">t</span></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span><span class="mclose">)</span></span></span></span></span></li>
<li>Para cada palavra <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><msub><mi>d</mi><mi>n</mi></msub></msub></mrow><annotation encoding="application/x-tex">W_{d_n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.93343em; vertical-align: -0.2501em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.164543em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2501em;"><span class=""></span></span></span></span></span></span></span></span></span></span> do documento:
<ul>
<li>Extrai um indicador do tema <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>Z</mi><msub><mi>d</mi><mi>n</mi></msub></msub><mo>∼</mo><mrow><mi mathvariant="normal">M</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi></mrow><mo stretchy="false">(</mo><msub><mi>θ</mi><mi>d</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z_{d_n} \sim \mathrm{Multinomial}(\theta_d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.93343em; vertical-align: -0.2501em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.07153em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.164543em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2501em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathrm">M</span><span class="mord mathrm">u</span><span class="mord mathrm">l</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">o</span><span class="mord mathrm">m</span><span class="mord mathrm">i</span><span class="mord mathrm">a</span><span class="mord mathrm">l</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></li>
<li>Extrai uma palavra <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><msub><mi>d</mi><mi>n</mi></msub></msub><mo>∼</mo><mrow><mi mathvariant="normal">M</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi></mrow><mo stretchy="false">(</mo><msub><mi>β</mi><msub><mi>Z</mi><msub><mi>d</mi><mi>n</mi></msub></msub></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">W_{d_n} \sim \mathrm{Multinomial}(\beta_{Z_{d_n}})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.93343em; vertical-align: -0.2501em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.164543em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2501em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.10586em; vertical-align: -0.35586em;"></span><span class="mord"><span class="mord mathrm">M</span><span class="mord mathrm">u</span><span class="mord mathrm">l</span><span class="mord mathrm">t</span><span class="mord mathrm">i</span><span class="mord mathrm">n</span><span class="mord mathrm">o</span><span class="mord mathrm">m</span><span class="mord mathrm">i</span><span class="mord mathrm">a</span><span class="mord mathrm">l</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: -0.05278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.34877em; margin-left: -0.07153em; margin-right: 0.0714286em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.23056em;"><span class="" style="top: -2.3em; margin-left: 0em; margin-right: 0.1em;"><span class="pstrut" style="height: 2.5em;"></span><span class="mord mathdefault mtight">n</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.294086em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.35586em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Observe que este modelo segue a hipótese do “saco de palavras” (<em>bag of words</em>), de forma que, dadas as proporções de temas, cada palavra extraída é independente das outras palavras do documento.</p>
<h4 id="guia-de-código">Guia de código</h4>
<p>Às vezes é útil ter o algoritmo em uma classe, de maneira que se houver vários conjuntos de dados, parâmetros e resultados, eles são mantidos separados uns dos outros.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">class</span> <span class="token class-name">SVILDA</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  

	<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> K<span class="token punctuation">,</span> D<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> eta<span class="token punctuation">,</span> tau<span class="token punctuation">,</span> kappa<span class="token punctuation">,</span> docs<span class="token punctuation">,</span> iterations<span class="token punctuation">)</span><span class="token punctuation">:</span> 
		self <span class="token punctuation">.</span>_vocab <span class="token operator">=</span> vocab  
		self <span class="token punctuation">.</span>_V <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span>  
		self <span class="token punctuation">.</span>_K <span class="token operator">=</span> K  
		self <span class="token punctuation">.</span>_D <span class="token operator">=</span> D  
		self <span class="token punctuation">.</span>_alpha  
		self <span class="token punctuation">.</span>_eta <span class="token operator">=</span>  
		self <span class="token punctuation">.</span>_tau <span class="token operator">=</span>  
		self <span class="token punctuation">.</span>_kappa  
		self <span class="token punctuation">.</span>_lambda <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">*</span> n<span class="token punctuation">.</span>random<span class="token punctuation">.</span>gamma<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_K<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_V<span class="token punctuation">)</span><span class="token punctuation">)</span>  
		self <span class="token punctuation">.</span>_Elogbeta <span class="token operator">=</span> dirichlet_expectation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_lambda<span class="token punctuation">)</span>  
		self <span class="token punctuation">.</span>_expElogbeta <span class="token operator">=</span> n<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_Elogbeta<span class="token punctuation">)</span>  
		self <span class="token punctuation">.</span>_docs <span class="token operator">=</span> docs  
		self<span class="token punctuation">.</span>ct <span class="token operator">=</span> <span class="token number">0</span>  
		self<span class="token punctuation">.</span>_iterations <span class="token operator">=</span> iterations
</code></pre>
<p>Nesta versão, assume-se que os dados não foram pré-processados e note também que <code>numpy</code> foi importado como <code>n</code>. Em seguida, é apresentada a função  <code>dirichet_expectation</code>. Esta função calcula a expectativa de uma distribuição <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span></span></span></span></span> tendo em conta seu parâmetro. É proveniente da implementação original de Matthew Hoffman em <a href="#refer%C3%AAncias">[3]</a>.</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">dirichlet_expectation</span><span class="token punctuation">(</span>alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>  
	<span class="token triple-quoted-string string">'''see onlineldavb.py by Matthew Hoffman'''</span> 
	 
	<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>alpha<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
		<span class="token keyword">return</span> <span class="token punctuation">(</span>psi<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span> <span class="token operator">-</span> psi<span class="token punctuation">(</span>n<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>alpha<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	
	<span class="token keyword">return</span> <span class="token punctuation">(</span>psi<span class="token punctuation">(</span>alpha<span class="token punctuation">)</span> <span class="token operator">-</span> psi<span class="token punctuation">(</span>n<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> n<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<p>A seguir, mostramos a atualização local e global. A função de atualização é muito parecida à do algoritmo original, por isso não será explicada em detalhes (ver <a href="#refer%C3%AAncias">[2]</a>). No entanto, a ideia chave é que a função <code>UpdateLocal</code> adote um documento analisado sintaticamente, atualize as variáveis locais primeiro e depois atualize os parâmetros globais, do seguinte modo:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">UpdateLocal</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> doc<span class="token punctuation">)</span><span class="token punctuation">:</span> 
	<span class="token punctuation">(</span>words<span class="token punctuation">,</span> counts<span class="token punctuation">)</span> <span class="token operator">=</span> doc 
	newdoc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  
	N_d <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>counts<span class="token punctuation">)</span>
	phi_d <span class="token operator">=</span> n<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_K<span class="token punctuation">,</span> N_d<span class="token punctuation">)</span><span class="token punctuation">)</span>  
	gamma_d <span class="token operator">=</span> n<span class="token punctuation">.</span>random<span class="token punctuation">.</span>gamma<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">/</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_K<span class="token punctuation">)</span><span class="token punctuation">)</span> 
	Elogtheta_d <span class="token operator">=</span> dirichlet_expectation<span class="token punctuation">(</span>gamma_d<span class="token punctuation">)</span> 
	expElogtheta_d <span class="token operator">=</span> n<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>Elogtheta_d<span class="token punctuation">)</span>  
	<span class="token keyword">for</span> i<span class="token punctuation">,</span> item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>counts<span class="token punctuation">)</span><span class="token punctuation">:</span>
		<span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span><span class="token punctuation">:</span> 
			newdoc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>words<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
	
	<span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>newdoc<span class="token punctuation">)</span> <span class="token operator">==</span> N_d<span class="token punctuation">,</span> <span class="token string">"error"</span>
	<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>  
		<span class="token keyword">for</span> m<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>newdoc<span class="token punctuation">)</span><span class="token punctuation">:</span>
			phi_d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> m<span class="token punctuation">]</span> <span class="token operator">=</span> n<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>expElogtheta_d<span class="token punctuation">,</span>self<span class="token punctuation">.</span>_expElogbeta<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> word<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">100</span>  
			phi_d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> m<span class="token punctuation">]</span> <span class="token operator">=</span> phi_d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> m<span class="token punctuation">]</span><span class="token operator">/</span>n<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>phi_d<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> m<span class="token punctuation">]</span><span class="token punctuation">)</span>

		gamma_new <span class="token operator">=</span> self<span class="token punctuation">.</span>_alpha <span class="token operator">+</span> n<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>phi_d<span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span> 
		meanchange <span class="token operator">=</span> n<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token builtin">abs</span><span class="token punctuation">(</span>gamma_d <span class="token operator">-</span> gamma_new<span class="token punctuation">)</span><span class="token punctuation">)</span> 
		<span class="token keyword">if</span> <span class="token punctuation">(</span>meanchange <span class="token operator">&lt;</span> meanchangethresh<span class="token punctuation">)</span><span class="token punctuation">:</span>
			<span class="token keyword">break</span>  
			
		gamma_d <span class="token operator">=</span> gamma_new
		Elogtheta_d <span class="token operator">=</span> dirichlet_expectation<span class="token punctuation">(</span>gamma_d<span class="token punctuation">)</span>
		expElogtheta_d <span class="token operator">=</span> n<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>Elogtheta_d<span class="token punctuation">)</span> 
		
	newdoc <span class="token operator">=</span> n<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>newdoc<span class="token punctuation">)</span>
	<span class="token keyword">return</span> phi_d<span class="token punctuation">,</span> newdoc<span class="token punctuation">,</span> gamma_d

<span class="token keyword">def</span> <span class="token function">UpdateGlobal</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> local_param<span class="token punctuation">,</span> doc<span class="token punctuation">)</span><span class="token punctuation">:</span> 
	lambda_d <span class="token operator">=</span> n<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_K<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_V<span class="token punctuation">)</span><span class="token punctuation">)</span> 
	<span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_K<span class="token punctuation">)</span><span class="token punctuation">:</span>
		phi_dk <span class="token operator">=</span> n<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_V<span class="token punctuation">)</span>  
		<span class="token keyword">for</span> m<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">:</span>
			phi_dk<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">+=</span> phi_d<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span>m<span class="token punctuation">]</span> 
		lambda_d<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_eta <span class="token operator">+</span> self<span class="token punctuation">.</span>_D <span class="token operator">*</span> phi_dk
	rho <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>ct <span class="token operator">+</span> self<span class="token punctuation">.</span>_tau<span class="token punctuation">)</span> <span class="token operator">**</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>_kappa<span class="token punctuation">)</span>
	self<span class="token punctuation">.</span>_lambda <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>rho<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>_lambda <span class="token operator">+</span> rho <span class="token operator">*</span> lambda_d 
	self<span class="token punctuation">.</span>_Elogbeta <span class="token operator">=</span> dirichlet_expectation<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_lambda<span class="token punctuation">)</span> 
	self<span class="token punctuation">.</span>_expElogbeta <span class="token operator">=</span> n<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_Elogbeta<span class="token punctuation">)</span>
</code></pre>
<p>Finalmente, pode-se escrever uma função geral para gerenciar todas as atualizações levando em consideração o atraso e a taxa de esquecimento, com as seguintes entradas:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">runSVI</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  
	<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>  
		randint <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_D<span class="token number">-1</span><span class="token punctuation">)</span>  
		<span class="token keyword">if</span>  self<span class="token punctuation">.</span>_parsed <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span> 
			doc <span class="token operator">=</span> parseDocument<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_docs<span class="token punctuation">[</span>randint<span class="token punctuation">]</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>_vocab<span class="token punctuation">)</span>
		phi_doc<span class="token punctuation">,</span> newdoc<span class="token punctuation">,</span> gamma_d <span class="token operator">=</span> self<span class="token punctuation">.</span>updateLocal<span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>updateGlobal<span class="token punctuation">(</span>phi_doc<span class="token punctuation">,</span> newdoc<span class="token punctuation">)</span>
		self<span class="token punctuation">.</span>ct <span class="token operator">+=</span> <span class="token number">1</span>
</code></pre>
<p>A função integrada <code>parseDocument</code> aqui é:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">def</span> <span class="token function">parseDocument</span><span class="token punctuation">(</span>doc<span class="token punctuation">,</span> vocab<span class="token punctuation">)</span><span class="token punctuation">:</span> 
	wordslist <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	countslist <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
	doc <span class="token operator">=</span> doc<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>  
	tokens <span class="token operator">=</span> wordpunct_tokenize<span class="token punctuation">(</span>doc<span class="token punctuation">)</span>  
	<span class="token keyword">for</span> word <span class="token keyword">in</span> tokens<span class="token punctuation">:</span> 
		<span class="token keyword">if</span> word <span class="token keyword">in</span> vocab<span class="token punctuation">:</span> 
			wordtk <span class="token operator">=</span> vocab<span class="token punctuation">[</span>word<span class="token punctuation">]</span>
			<span class="token keyword">if</span> wordtk <span class="token operator">not</span> <span class="token keyword">in</span> dictionary<span class="token punctuation">:</span> 
				dictionary<span class="token punctuation">[</span>wordtk<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> 
			<span class="token keyword">else</span><span class="token punctuation">:</span> 
				dictionary<span class="token punctuation">[</span>wordtk<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
	wordslist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dictionary<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	countslist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dictionary<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">return</span> <span class="token punctuation">(</span>wordslist<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> countslist<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
</code></pre>
<p>Existem também outras funções no código que se aplicam e podem ser encontradas no  <a href="https://drive.google.com/file/d/1wsetPOOjohkJPuM-YoKGxm_EpRodrO1X/view?usp=sharing"><em>notebook</em></a> do estudo de caso. Por exemplo, poderíamos incluir certo código que permitiria “traçar” a alteração dos valores de certas variáveis para poder visualizar a convergência desse valor.</p>
<h3 id="visualização-dos-resultados">Visualização dos resultados</h3>
<p>Há muitas maneiras de visualizar os resultados quando se consegue fazer as distribuições do vocabulário por temas. A primeira informação que pode ser obtida é ver quais são as palavras mais populares em cada tema. Para isso, pode-se usar o exemplo a seguir e, em seguida, ao extrair cada entrada de tema, podemos classificar as palavras em ordem de probabilidade mais alta para a mais baixa. É assim que se chega à lista de palavras para cada tema, que aparece nas laterais da Figura 1.</p>
<p>Outra visualização fácil é ver a distribuição de temas em geral nos documentos. Para isso, você pode analisar cada documento, inferir como os temas são distribuídos nesse documento e, em seguida, somar as probabilidades dos temas em todos os documentos. Foi assim que se chegou ao gráfico de pizza que representa as proporções dos temas no centro da Figura 1.</p>
<figure>
	<img src="https://drive.google.com/uc?export=view&amp;id=1auOUtsRJ-r3qwa1mCw2uM1-HC5qiBxY8">
	<figcaption><b>Figura 1.</b> Distribuição de temas e as palavras mais comuns para um exemplo em que K = 5.</figcaption>
</figure>
<p>Em terceiro lugar, também é possível inferir, usando <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">λ</span></span></span></span></span> , a distribuição de temas para cada documento, e utilizar esta informação para adivinhar a abordagem principal de cada publicação extraída de <a href="https://arxiv.org/"><em>arXiv</em></a>. Uma forma de fazer isso é: para cada tema, soma-se a probabilidade normalizada de cada palavra (palavras menos usadas terão menor peso) nesse tema em relação a todas as palavras do documento e, em seguida, se compara este valor em todos os temas.</p>
<p>Por fim, observe que há mais de um artigo por autor e muitos autores por laboratório. Para encontrar a distribuição de temas em um laboratório, pode-se coletar todas as distribuições de temas dos artigos que pertencem aos autores desse laboratório. É assim que se chega às distribuições de temas para cada um dos quatro laboratórios na Figura 2.</p>
<figure>
	<img src="https://drive.google.com/uc?export=view&amp;id=1mD6ucZ8LRGIcVl0aJGZIM-tkv7M9E3Al">
	<figcaption><b>Figura 2.</b> Proporções de temas para os diferentes grupos de laboratórios, K = 5.</figcaption>
</figure>
<h3 id="referências">Referências</h3>
<ol>
<li>Blei, D., Ng, A., y Jordan, M. (2003). “Latent Dirichlet allocation”, Journal of Machine Learning Research, 3: 993-1022.</li>
<li>Hoffman, M., Blei, D., Wang, C., y Paisley, J. (2013). “Stochastic variational inference”, Journal of Machine Learning Research, 14:1303-1347.</li>
<li>Hoffman, M. D. (2010). Inferências bayesianas online para LDA. <a href="https://github.com/blei-lab/onlineldavb">https://github.com/blei-lab/onlineldavb</a></li>
<li>Lai, Q. (2016). Implementação em Python de IVE para LDA. <a href="https://github.com/qlai/stochasticLDA">https://github.com/qlai/stochasticLDA</a></li>
<li>D. Hoffman, Matthew, M. Blei, David y Bach, Francis. (2010). “Online Learning for Latent Dirichlet Allocation”, Advances in Neural Information Processing Systems, 23, 856-564</li>
</ol>
<hr>
<img src="https://drive.google.com/uc?export=view&amp;id=1du2bbjAM4VMziHc2jl9Etk7q26IxuLyy">
<p>©2021 Massachusetts Institute of Technology</p>
<!--stackedit_data:&#10;eyJoaXN0b3J5IjpbNjAzNDM1MzMsLTIxMzgyMTAxODQsMTQ2NT&#10;I4ODI3OCw0ODA0OTk0MDAsLTEzOTEzMTgzMTQsMjA4NTE3ODg1&#10;NCwtMTUzNjg5NTUxMyw3MzA5OTgxMTZdfQ==&#10;-->
</div>
</body>

</html>
